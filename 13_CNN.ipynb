{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer, Dense, GlobalMaxPool1D, Conv1D\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## Dataset\n",
    "dataset = [\n",
    "    \"မြန်မာ ပြည် ရှေ့ရေး အကြောင်း ဆွေးနွေးသွားတာ အရမ်း ကောင်းတယ်။\", \n",
    "    \"အရမ်း မှန်တဲ့ စကားတွေပါ။ ကျေးဇူး တင်ပါတယ်။\", \n",
    "    \"တန်ဖိုး ရှိတဲ့ စကားတွေပါ။ လေးစားပါတယ်။\", \n",
    "    \"သုံးသပ်သွားတာ ကောင်းလိုက်တာ။ အရမ်း ဗဟုသုတ ရတယ်။\", \n",
    "    \"ကျေးဇူးပါ ဆရာ သုံးသပ်ချက် တွေကို ကျေနပ် အားရပါတယ်။\", \n",
    "\n",
    "    \"မင်းဆိုး မင်းညစ် အယုတ်တမာ ကျဆုံးမှာပါ။\", \n",
    "    \"ကလိမ်ကကျစ် နဲ့ စကား ကို ဝေ့ဝိုက်ပြီး ပြောနေတယ်။\", \n",
    "    \"မိုက်ရိုက်လိုက်တဲ့ လုပ်ရပ်ဗျာ။ အတော် ဆိုးတာပဲ။\", \n",
    "    \"ကျက်သရေ တုံးပါကွာ။ အရည်အချင်းကို မရှိဘူး။\", \n",
    "    \"မင်းကို မြင်ရတာ စိတ် ကသိကအောက် ဖြစ်တယ်။\", \n",
    "\n",
    "    \"ပြည်ထောင်စု သမ္မတ မြန်မာ နိုင်ငံတော် ထာဝရ တည်တံ့နိုင်ပါစေ။\", \n",
    "    \"ပြည်ထောင်စု ဖွား တိုင်းရင်းသားတွေ စုစည်းနေရင် အရမ်း ကောင်းမှာပဲ။\", \n",
    "    \"စစ်ပွဲတွေ ကို မုန်းလိုက်တာ ဗျာ။\", \n",
    "    \"စာသင်ကျောင်း တံခါးများ အမြဲတမ်း ဖွင့်ထားနိုင်ပါစေ။\", \n",
    "    \"ရခိုင် မုန့်တီ၊ ရှမ်း ခေါက်ဆွဲ နဲ့ ကရင် ကုတိယို ကို အရမ်း ကြိုက်တယ်။\" \n",
    "]\n",
    "targets = [\"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Negative\", \"Negative\", \"Negative\", \"Negative\", \"Negative\", \"Neutral\", \"Neutral\", \"Neutral\", \"Neutral\", \"Neutral\"]\n",
    "\n",
    "## Parameters\n",
    "VOCAB_SIZE = 100\n",
    "MAX_LENGTH = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[95, 67, 28, 77, 19, 14, 16],\n",
       " [14, 31, 11, 34, 58],\n",
       " [87, 42, 11, 12],\n",
       " [9, 54, 14, 36, 55],\n",
       " [79, 87, 44, 81, 79, 55],\n",
       " [80, 61, 92, 39],\n",
       " [83, 33, 75, 86, 93, 72],\n",
       " [83, 59, 83, 74],\n",
       " [41, 16, 93, 10],\n",
       " [10, 87, 25, 70, 86],\n",
       " [89, 16, 95, 41, 93, 81],\n",
       " [89, 19, 71, 40, 14, 23],\n",
       " [97, 86, 26, 37],\n",
       " [67, 84, 37, 45],\n",
       " [18, 5, 27, 81, 33, 54, 21, 86, 14, 33]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert documents to one-hot encoded representation\n",
    "encoded_docs = [one_hot(doc, VOCAB_SIZE) for doc in dataset]\n",
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding : [[95 67 28 77 19 14 16  0  0  0  0  0  0  0  0]\n",
      " [14 31 11 34 58  0  0  0  0  0  0  0  0  0  0]\n",
      " [87 42 11 12  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 9 54 14 36 55  0  0  0  0  0  0  0  0  0  0]\n",
      " [79 87 44 81 79 55  0  0  0  0  0  0  0  0  0]\n",
      " [80 61 92 39  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [83 33 75 86 93 72  0  0  0  0  0  0  0  0  0]\n",
      " [83 59 83 74  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [41 16 93 10  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [10 87 25 70 86  0  0  0  0  0  0  0  0  0  0]\n",
      " [89 16 95 41 93 81  0  0  0  0  0  0  0  0  0]\n",
      " [89 19 71 40 14 23  0  0  0  0  0  0  0  0  0]\n",
      " [97 86 26 37  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [67 84 37 45  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [18  5 27 81 33 54 21 86 14 33  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences to ensure consistent input size\n",
    "pad_sentences = pad_sequences(encoded_docs, maxlen=MAX_LENGTH, padding='post')\n",
    "print(f\"Padding : {pad_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels : [2 2 2 2 2 0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the target labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_lbls = encoder.fit_transform(targets)\n",
    "print(f'Encoded labels : {encoded_lbls}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Embedding Class (Modified for Keras Model)\n",
    "class CustomEmbedding(Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(CustomEmbedding, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initialize embedding matrix with random values\n",
    "        self.embeddings = self.add_weight(\n",
    "            name='embeddings',\n",
    "            shape=(self.input_dim, self.output_dim),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Lookup embeddings for each index in the input sequence\n",
    "        return tf.gather(self.embeddings, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " custom_embedding (CustomEmb  (1, 15, 10)              1000      \n",
      " edding)                                                         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (1, 11, 128)              6528      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (1, 128)                 0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (1, 3)                    387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,915\n",
      "Trainable params: 7,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Create CNN Model with CustomEmbedding\n",
    "model = Sequential()\n",
    "model.add(CustomEmbedding(input_dim=VOCAB_SIZE, output_dim=10))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Now, we call the model on a batch of data to ensure the model is built\n",
    "model(np.zeros((1, MAX_LENGTH), dtype=np.int32))  # Pass a dummy batch with integer data\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.0995 - accuracy: 0.2667\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0925 - accuracy: 0.3333\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.8000\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0796 - accuracy: 0.8667\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0735 - accuracy: 0.8667\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0676 - accuracy: 0.8667\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0617 - accuracy: 0.9333\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0558 - accuracy: 0.9333\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0500 - accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0440 - accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0380 - accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0320 - accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0259 - accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0197 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0133 - accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0067 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9999 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9930 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9858 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9783 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9705 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9624 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9455 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9366 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9273 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9077 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8974 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8867 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8756 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8521 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8398 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8272 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8141 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8005 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7865 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7721 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7263 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7103 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2918 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2228 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1875 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1768 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1569 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f75bcd6f20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Train Model\n",
    "model.fit(pad_sentences, encoded_lbls, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0, Loss : 0.008903194218873978\n"
     ]
    }
   ],
   "source": [
    "## Model Evaluation\n",
    "loss, acc = model.evaluate(pad_sentences, encoded_lbls, verbose=0)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy : {acc}, Loss : {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'တန်ဖိုး ရှိတဲ့ စကားတွေပါ။ လေးစားပါတယ်။' -> Positive\n",
      "'မိုက်ရိုက်လိုက်တဲ့ လုပ်ရပ်ဗျာ။ အတော် ဆိုးတာပဲ။' -> Negative\n",
      "'စာသင်ကျောင်း တံခါးများ အမြဲတမ်း ဖွင့်ထားနိုင်ပါစေ။' -> Neutral\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    \"တန်ဖိုး ရှိတဲ့ စကားတွေပါ။ လေးစားပါတယ်။\", \n",
    "    \"မိုက်ရိုက်လိုက်တဲ့ လုပ်ရပ်ဗျာ။ အတော် ဆိုးတာပဲ။\",\n",
    "    \"စာသင်ကျောင်း တံခါးများ အမြဲတမ်း ဖွင့်ထားနိုင်ပါစေ။\"\n",
    "]\n",
    "encoded_test_docs = [one_hot(doc, VOCAB_SIZE) for doc in test]\n",
    "pad_test_sentences = pad_sequences(encoded_test_docs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "## Predict using the trained model\n",
    "predictions = model.predict(pad_test_sentences, verbose=0)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_classes = encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "## Print the predictions\n",
    "for i, sentence in enumerate(test):\n",
    "    print(f\"'{sentence}' -> {predicted_classes[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
