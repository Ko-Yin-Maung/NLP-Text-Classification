{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length : 15\n",
      "Tokenized Text : [['မြန်မာ', 'ပြည်', 'ရှေ့ရေး', 'အကြောင်း', 'ဆွေးနွေးသွားတာ', 'အရမ်း', 'ကောင်းတယ်'], ['အရမ်း', 'မှန်တဲ့', 'စကားတွေပါ', 'ကျေးဇူး', 'တင်ပါတယ်'], ['တန်ဖိုး', 'ရှိတဲ့', 'စကားတွေပါ', 'လေးစားပါတယ်'], ['သုံးသပ်သွားတာ', 'ကောင်းလိုက်တာ', 'အရမ်း', 'ဗဟုသုတ', 'ရတယ်'], ['ကျေးဇူးပါ', 'ဆရာ', 'သုံးသပ်ချက်', 'တွေကို', 'ကျေနပ်', 'အားရပါတယ်']]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "## Dataset preparation\n",
    "dataset = [ \n",
    "    \"မြန်မာ ပြည် ရှေ့ရေး အကြောင်း ဆွေးနွေးသွားတာ အရမ်း ကောင်းတယ်။\", \n",
    "    \"အရမ်း မှန်တဲ့ စကားတွေပါ။ ကျေးဇူး တင်ပါတယ်။\", \n",
    "    \"တန်ဖိုး ရှိတဲ့ စကားတွေပါ။ လေးစားပါတယ်။\", \n",
    "    \"သုံးသပ်သွားတာ ကောင်းလိုက်တာ။ အရမ်း ဗဟုသုတ ရတယ်။\", \n",
    "    \"ကျေးဇူးပါ ဆရာ သုံးသပ်ချက် တွေကို ကျေနပ် အားရပါတယ်။\", \n",
    "\n",
    "    \"မင်းဆိုး မင်းညစ် အယုတ်တမာ ကျဆုံးမှာပါ။\", \n",
    "    \"ကလိမ်ကကျစ် နဲ့ စကား ကို ဝေ့ဝိုက်ပြီး ပြောနေတယ်။\", \n",
    "    \"မိုက်ရိုက်လိုက်တဲ့ လုပ်ရပ်ဗျာ။ အတော် ဆိုးတာပဲ။\", \n",
    "    \"ကျက်သရေ တုံးပါကွာ။ အရည်အချင်းကို မရှိဘူး။\", \n",
    "    \"မင်းကို မြင်ရတာ စိတ် ကသိကအောက် ဖြစ်တယ်။\", \n",
    "\n",
    "    \"ပြည်ထောင်စု သမ္မတ မြန်မာ နိုင်ငံတော် ထာဝရ တည်တံ့နိုင်ပါစေ။\", \n",
    "    \"ပြည်ထောင်စု ဖွား တိုင်းရင်းသားတွေ စုစည်းနေရင် အရမ်း ကောင်းမှာပဲ။\", \n",
    "    \"စစ်ပွဲတွေ ကို မုန်းလိုက်တာ ဗျာ။\", \n",
    "    \"စာသင်ကျောင်း တံခါးများ အမြဲတမ်း ဖွင့်ထားနိုင်ပါစေ။\", \n",
    "    \"ရခိုင် မုန့်တီ၊ ရှမ်း ခေါက်ဆွဲ နဲ့ ကရင် ကုတိယို ကို အရမ်း ကြိုက်တယ်။\" \n",
    "] \n",
    "targets = [\"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Negative\", \"Negative\", \"Negative\", \"Negative\", \"Negative\", \"Neutral\", \"Neutral\", \"Neutral\", \"Neutral\", \"Neutral\"]\n",
    "\n",
    "## Tokenization\n",
    "tokenized_dataset = [doc.replace('၊', '').replace('။', '').lower().split() for doc in dataset]\n",
    "print(f'Dataset Length : {len(tokenized_dataset)}')\n",
    "print(f'Tokenized Text : {tokenized_dataset[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels: [2 2 2 2 2 0 0 0 0 0 1 1 1 1 1]\n",
      "Classes: ['Negative' 'Neutral' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "## Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(targets)\n",
    "print(\"Encoded Labels:\", encoded_labels)\n",
    "print(\"Classes:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BM25 Calculation Parameters\n",
    "k1 = 1.5  # term frequency saturation parameter\n",
    "b = 0.75  # length normalization parameter\n",
    "\n",
    "## BM25 Functions\n",
    "def compute_tf(doc):\n",
    "    term_count = Counter(doc)\n",
    "    return term_count\n",
    "\n",
    "def compute_df(corpus):\n",
    "    df = Counter()\n",
    "    for doc in corpus:\n",
    "        unique_terms = set(doc)\n",
    "        for term in unique_terms:\n",
    "            df[term] += 1\n",
    "    return df\n",
    "\n",
    "def compute_bm25(tf, df, corpus_size, avg_doc_len, doc_len, k1=1.5, b=0.75):\n",
    "    bm25 = {}\n",
    "    for term, term_freq in tf.items():\n",
    "        df_term = df.get(term, 0)\n",
    "        idf = math.log((corpus_size - df_term + 0.5) / (df_term + 0.5) + 1)  # BM25 IDF\n",
    "        norm_tf = (term_freq * (k1 + 1)) / (term_freq + k1 * (1 - b + b * (doc_len / avg_doc_len)))\n",
    "        bm25[term] = norm_tf * idf\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF for the entire corpus : Counter({'အရမ်း': 5, 'ကို': 3, 'မြန်မာ': 2, 'စကားတွေပါ': 2, 'နဲ့': 2, 'ပြည်ထောင်စု': 2, 'ဆွေးနွေးသွားတာ': 1, 'ပြည်': 1, 'ရှေ့ရေး': 1, 'အကြောင်း': 1, 'ကောင်းတယ်': 1, 'တင်ပါတယ်': 1, 'မှန်တဲ့': 1, 'ကျေးဇူး': 1, 'လေးစားပါတယ်': 1, 'ရှိတဲ့': 1, 'တန်ဖိုး': 1, 'ဗဟုသုတ': 1, 'ကောင်းလိုက်တာ': 1, 'ရတယ်': 1, 'သုံးသပ်သွားတာ': 1, 'ဆရာ': 1, 'ကျေးဇူးပါ': 1, 'အားရပါတယ်': 1, 'တွေကို': 1, 'သုံးသပ်ချက်': 1, 'ကျေနပ်': 1, 'မင်းညစ်': 1, 'အယုတ်တမာ': 1, 'မင်းဆိုး': 1, 'ကျဆုံးမှာပါ': 1, 'စကား': 1, 'ဝေ့ဝိုက်ပြီး': 1, 'ကလိမ်ကကျစ်': 1, 'ပြောနေတယ်': 1, 'လုပ်ရပ်ဗျာ': 1, 'မိုက်ရိုက်လိုက်တဲ့': 1, 'ဆိုးတာပဲ': 1, 'အတော်': 1, 'တုံးပါကွာ': 1, 'ကျက်သရေ': 1, 'အရည်အချင်းကို': 1, 'မရှိဘူး': 1, 'ကသိကအောက်': 1, 'စိတ်': 1, 'မြင်ရတာ': 1, 'ဖြစ်တယ်': 1, 'မင်းကို': 1, 'နိုင်ငံတော်': 1, 'တည်တံ့နိုင်ပါစေ': 1, 'သမ္မတ': 1, 'ထာဝရ': 1, 'တိုင်းရင်းသားတွေ': 1, 'ဖွား': 1, 'စုစည်းနေရင်': 1, 'ကောင်းမှာပဲ': 1, 'စစ်ပွဲတွေ': 1, 'မုန်းလိုက်တာ': 1, 'ဗျာ': 1, 'စာသင်ကျောင်း': 1, 'အမြဲတမ်း': 1, 'ဖွင့်ထားနိုင်ပါစေ': 1, 'တံခါးများ': 1, 'ရခိုင်': 1, 'ကရင်': 1, 'ရှမ်း': 1, 'မုန့်တီ': 1, 'ကုတိယို': 1, 'ခေါက်ဆွဲ': 1, 'ကြိုက်တယ်': 1})\n"
     ]
    }
   ],
   "source": [
    "## Calculate the document frequencies for the entire corpus\n",
    "df = compute_df(tokenized_dataset)\n",
    "print(f'DF for the entire corpus : {df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 feature of index 0 : {'မြန်မာ': 1.627439334019179, 'ပြည်': 2.0752864562249793, 'ရှေ့ရေး': 2.0752864562249793, 'အကြောင်း': 2.0752864562249793, 'ဆွေးနွေးသွားတာ': 2.0752864562249793, 'အရမ်း': 0.9361890454806409, 'ကောင်းတယ်': 2.0752864562249793}\n"
     ]
    }
   ],
   "source": [
    "## Compute average document length\n",
    "avg_doc_len = sum(len(doc) for doc in tokenized_dataset) / len(tokenized_dataset)\n",
    "\n",
    "## Compute BM25 for each document\n",
    "bm25_dataset = []\n",
    "for doc in tokenized_dataset:\n",
    "    tf = compute_tf(doc)\n",
    "    bm25 = compute_bm25(tf, df, len(tokenized_dataset), avg_doc_len, len(doc), k1, b)\n",
    "    bm25_dataset.append(bm25)\n",
    "    \n",
    "print(f'BM25 feature of index 0 : {bm25_dataset[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size : 70\n",
      "10th Sample : ပြည်ထောင်စု သမ္မတ မြန်မာ နိုင်ငံတော် ထာဝရ တည်တံ့နိုင်ပါစေ။\n",
      "BM25 Features 10th sample : [0.0, 0.0, 0.0, 0.0, 1.7574418843698236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7574418843698236, 2.241063776692655, 2.241063776692655, 2.241063776692655, 2.241063776692655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "## Convert BM25 dictionary to feature vectors\n",
    "vocabulary = list(df.keys())\n",
    "def vectorize(bm25, vocab):\n",
    "    return [bm25.get(term, 0.0) for term in vocab]\n",
    "\n",
    "features = [vectorize(bm25, vocabulary) for bm25 in bm25_dataset]\n",
    "print(f'Vocab Size : {vocabulary.__len__()}')\n",
    "print(f'10th Sample : {dataset[10]}')\n",
    "print(f'BM25 Features 10th sample : {features[10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.12250406971052717\n"
     ]
    }
   ],
   "source": [
    "## Classifier\n",
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_A = np.linalg.norm(A)\n",
    "    norm_B = np.linalg.norm(B)\n",
    "    return dot_product / (norm_A * norm_B)\n",
    "\n",
    "similarity = cosine_similarity(features[10], features[11])\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label : Negative\n"
     ]
    }
   ],
   "source": [
    "## Inference\n",
    "test = \"မင်းဆိုး မင်းညစ် အယုတ်တမာ တို့သည် ကျရှုံးကြစမြဲ ဖြစ်သည်။\"\n",
    "test_tf = compute_tf(test.replace('၊', '').replace('။', '').lower().split())\n",
    "test_bm25 = compute_bm25(test_tf, df, len(tokenized_dataset), avg_doc_len, len(test_tf), k1, b)\n",
    "test_vector = vectorize(test_bm25, vocabulary)\n",
    "preds = [cosine_similarity(source, test_vector) for source in features]\n",
    "idx = encoded_labels[np.argmax(preds)]\n",
    "print(f'Predicted Label : {label_encoder.classes_[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
